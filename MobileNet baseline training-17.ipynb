{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-26T14:02:29.385665Z","iopub.execute_input":"2023-04-26T14:02:29.386947Z","iopub.status.idle":"2023-04-26T14:02:37.489403Z","shell.execute_reply.started":"2023-04-26T14:02:29.386801Z","shell.execute_reply":"2023-04-26T14:02:37.488038Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_logical_devices('GPU') \nstg=tf.distribute.MirroredStrategy(gpus)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:37.491446Z","iopub.execute_input":"2023-04-26T14:02:37.492118Z","iopub.status.idle":"2023-04-26T14:02:37.534328Z","shell.execute_reply.started":"2023-04-26T14:02:37.492079Z","shell.execute_reply":"2023-04-26T14:02:37.533153Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"folder_path = \"/kaggle/input/emotionv7/facemo/images/\" \n# folder_path = \"../input/face-expression-recognition-dataset/images/\"\n# validation_folder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:37.535876Z","iopub.execute_input":"2023-04-26T14:02:37.538670Z","iopub.status.idle":"2023-04-26T14:02:37.544457Z","shell.execute_reply.started":"2023-04-26T14:02:37.538620Z","shell.execute_reply":"2023-04-26T14:02:37.543232Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nfrom tqdm import tqdm\n\nfolder_dir = '/kaggle/input/emotionv7/facemo/images/train'\nSIZE = (48,48) \nDOWNSAMPLE_RATIO = 4\nJPEG_QUALITY = 80\n\n# get the total number of files to process\ntotal_files = sum(len(files) for _, _, files in os.walk(folder_dir))\n\n# use tqdm to display a progress bar\nwith tqdm(total=total_files, desc=\"Processing Images\") as pbar:\n    for folder in os.listdir(folder_dir):\n        for file in os.listdir(os.path.join(folder_dir, folder)):\n            if file.endswith(\"jpg\"):\n                image_path = os.path.join(folder_dir, folder, file)\n                img = cv2.imread(image_path)\n                img_resized = cv2.resize(img, (SIZE))\n                cv2.imwrite(image_path, img_resized)\n                pbar.update(1) # increment the progress bar\n            else:\n                continue\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:37.547847Z","iopub.execute_input":"2023-04-26T14:02:37.548791Z","iopub.status.idle":"2023-04-26T14:02:48.423125Z","shell.execute_reply.started":"2023-04-26T14:02:37.548750Z","shell.execute_reply":"2023-04-26T14:02:48.421815Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Processing Images: 100%|██████████| 2827/2827 [00:10<00:00, 280.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nexpression = 'happy'\nplt.style.use('dark_background')\nplt.figure(figsize=(12, 12))\nfor i in range(1, 10):\n    plt.subplot(3, 3, i)\n    img = load_img(folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i], target_size=SIZE)\n    plt.imshow(img)  \nplt.show()\n'''","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-26T14:02:48.424645Z","iopub.execute_input":"2023-04-26T14:02:48.425084Z","iopub.status.idle":"2023-04-26T14:02:48.434925Z","shell.execute_reply.started":"2023-04-26T14:02:48.425055Z","shell.execute_reply":"2023-04-26T14:02:48.433773Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nexpression = \\'happy\\'\\nplt.style.use(\\'dark_background\\')\\nplt.figure(figsize=(12, 12))\\nfor i in range(1, 10):\\n    plt.subplot(3, 3, i)\\n    img = load_img(folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i], target_size=SIZE)\\n    plt.imshow(img)  \\nplt.show()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 32\npicture_size = SIZE\ndatagen_train = ImageDataGenerator(rotation_range=.5, \n                                    width_shift_range=0.2, \n                                    height_shift_range=0.2, \n                                    zoom_range=0.2, \n                                    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input \n                                )\n\ndatagen_val = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input )\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                    rotation_range=.5,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    zoom_range=0.2,\n                                    fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:48.437097Z","iopub.execute_input":"2023-04-26T14:02:48.437769Z","iopub.status.idle":"2023-04-26T14:02:48.449814Z","shell.execute_reply.started":"2023-04-26T14:02:48.437725Z","shell.execute_reply":"2023-04-26T14:02:48.448636Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(folder_path + 'train',\n                                                    target_size=(picture_size),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')\n\nvalidation_set = test_datagen.flow_from_directory(folder_path + 'validation',\n                                                        target_size=(picture_size),\n                                                        batch_size=batch_size,\n                                                        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:48.451545Z","iopub.execute_input":"2023-04-26T14:02:48.452391Z","iopub.status.idle":"2023-04-26T14:02:48.688940Z","shell.execute_reply.started":"2023-04-26T14:02:48.452342Z","shell.execute_reply":"2023-04-26T14:02:48.687462Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 2827 images belonging to 5 classes.\nFound 797 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nfrom tensorflow.keras.optimizers import RMSprop,SGD,Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n\nno_of_classes = 5\n\nwith stg.scope():\n    base_model = tf.keras.applications.MobileNetV2(input_shape=(48,48,3),\n                                                   include_top=False,\n                                                   weights=None)\n\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(no_of_classes, activation='softmax'))\n\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=Adam(lr=0.001),\n        metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:05:04.453246Z","iopub.execute_input":"2023-04-26T14:05:04.454691Z","iopub.status.idle":"2023-04-26T14:05:06.949082Z","shell.execute_reply.started":"2023-04-26T14:05:04.454643Z","shell.execute_reply":"2023-04-26T14:05:06.947674Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_48 (Functio (None, 2, 2, 1280)        2257984   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               655872    \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 2,980,165\nTrainable params: 2,946,053\nNon-trainable params: 34,112\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss',\n                                patience=3,\n                                verbose=1,\n                                restore_best_weights=True)\n\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n                                factor=0.1,\n                                patience=2,\n                                verbose=1)\n\ncallbacks = [early_stopping, lr_scheduler]","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:05:09.928655Z","iopub.execute_input":"2023-04-26T14:05:09.929107Z","iopub.status.idle":"2023-04-26T14:05:09.935028Z","shell.execute_reply.started":"2023-04-26T14:05:09.929070Z","shell.execute_reply":"2023-04-26T14:05:09.934181Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                    steps_per_epoch=train_generator.n // batch_size,\n                    epochs=20,\n                    validation_data=validation_set,\n                    validation_steps=validation_set.n // batch_size,\n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:05:12.506117Z","iopub.execute_input":"2023-04-26T14:05:12.506567Z","iopub.status.idle":"2023-04-26T14:12:27.386518Z","shell.execute_reply.started":"2023-04-26T14:05:12.506529Z","shell.execute_reply":"2023-04-26T14:12:27.385221Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/20\n88/88 [==============================] - 49s 319ms/step - loss: 1.6041 - accuracy: 0.2680 - val_loss: 1.6101 - val_accuracy: 0.2227\nEpoch 2/20\n88/88 [==============================] - 23s 255ms/step - loss: 1.4428 - accuracy: 0.3717 - val_loss: 1.6133 - val_accuracy: 0.1042\nEpoch 3/20\n88/88 [==============================] - 23s 264ms/step - loss: 1.2459 - accuracy: 0.4927 - val_loss: 1.6116 - val_accuracy: 0.2201\n\nEpoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 4/20\n88/88 [==============================] - 23s 263ms/step - loss: 1.0767 - accuracy: 0.5703 - val_loss: 1.6039 - val_accuracy: 0.2201\nEpoch 5/20\n88/88 [==============================] - 23s 262ms/step - loss: 1.0105 - accuracy: 0.5989 - val_loss: 1.5998 - val_accuracy: 0.2240\nEpoch 6/20\n88/88 [==============================] - 23s 259ms/step - loss: 0.9360 - accuracy: 0.6293 - val_loss: 1.5989 - val_accuracy: 0.2227\nEpoch 7/20\n88/88 [==============================] - 23s 253ms/step - loss: 0.8878 - accuracy: 0.6558 - val_loss: 1.5980 - val_accuracy: 0.2227\nEpoch 8/20\n88/88 [==============================] - 23s 260ms/step - loss: 0.8410 - accuracy: 0.6805 - val_loss: 1.5969 - val_accuracy: 0.1706\nEpoch 9/20\n88/88 [==============================] - 23s 263ms/step - loss: 0.7767 - accuracy: 0.7009 - val_loss: 1.5988 - val_accuracy: 0.1693\nEpoch 10/20\n88/88 [==============================] - 23s 263ms/step - loss: 0.7259 - accuracy: 0.7206 - val_loss: 1.6000 - val_accuracy: 0.1719\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\nEpoch 11/20\n88/88 [==============================] - 22s 251ms/step - loss: 0.7113 - accuracy: 0.7277 - val_loss: 1.5995 - val_accuracy: 0.1732\nRestoring model weights from the end of the best epoch.\nEpoch 00011: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(validation_set)\nprint('Test accuracy:', test_acc)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-04-26T14:16:46.075644Z","iopub.execute_input":"2023-04-26T14:16:46.076127Z","iopub.status.idle":"2023-04-26T14:16:46.177024Z","shell.execute_reply.started":"2023-04-26T14:16:46.076032Z","shell.execute_reply":"2023-04-26T14:16:46.175243Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3205073307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model.save('/kaggle/working/my_model_emo.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:49.042518Z","iopub.status.idle":"2023-04-26T14:02:49.042918Z","shell.execute_reply.started":"2023-04-26T14:02:49.042730Z","shell.execute_reply":"2023-04-26T14:02:49.042748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\ne = ['Angry','Happy','Neutral','Sad','Surprise']\nfor i in range(len(e)):\n    print(i,\"=\",e[i])\n# Get a batch of 10 random images from the test set\ntest_batch = validation_set.next()\nimages = test_batch[0][:10]\ntrue_labels = test_batch[1][:10]\n\n# Make predictions using the trained model\npred_probs = model.predict(images)\npred_labels = np.argmax(pred_probs, axis=1)\n\n# Plot the images with their true and predicted labels\nfig, axs = plt.subplots(2, 5, figsize=(15, 7))\naxs = axs.flatten()\n\nfor i in range(len(images)):\n    # Rescale the pixel values from [0, 1] to [0, 255] and convert to integers\n    img = (images[i] * 255).astype(np.uint8)\n    # Invert the pixel values\n    img = 255 - img\n    axs[i].imshow(img)\n    axs[i].set_title(f'True: {true_labels[i]}, Pred: {pred_labels[i]}')\n    axs[i].axis('off')\n\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:02:49.044401Z","iopub.status.idle":"2023-04-26T14:02:49.045521Z","shell.execute_reply.started":"2023-04-26T14:02:49.045279Z","shell.execute_reply":"2023-04-26T14:02:49.045302Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
