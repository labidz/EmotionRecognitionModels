{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n# Importing Deep Learning Libraries\n\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nimport tensorflow as tf\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T12:49:05.461167Z","iopub.execute_input":"2023-04-27T12:49:05.461863Z","iopub.status.idle":"2023-04-27T12:49:12.425332Z","shell.execute_reply.started":"2023-04-27T12:49:05.461750Z","shell.execute_reply":"2023-04-27T12:49:12.424306Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_logical_devices('GPU') \nstg=tf.distribute.MirroredStrategy(gpus)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:12.427177Z","iopub.execute_input":"2023-04-27T12:49:12.427879Z","iopub.status.idle":"2023-04-27T12:49:15.306631Z","shell.execute_reply.started":"2023-04-27T12:49:12.427844Z","shell.execute_reply":"2023-04-27T12:49:15.305679Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# folder_path = \"../input/ckplus/CK+48/\" \n# validation_folder_path = \"../input/dataset2-modified-copy-2/dataset(2) - modified - Copy 2/images/\"\n# folder_path = \"../input/dataset2-modified-copy-2/dataset(2) - modified - Copy 2/images/\" \n# folder_path = \"../input/dataset-1-modified/dataset(1) - modified/images/\" \nfolder_path = \"/kaggle/input/emotionv7/facemo/images/\" \n# folder_path = \"../input/face-expression-recognition-dataset/images/\"\n# validation_folder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:15.310257Z","iopub.execute_input":"2023-04-27T12:49:15.310558Z","iopub.status.idle":"2023-04-27T12:49:15.317485Z","shell.execute_reply.started":"2023-04-27T12:49:15.310532Z","shell.execute_reply":"2023-04-27T12:49:15.316313Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport cv2\nimport os\n\nfolder_dir = '/kaggle/input/emotionv7/facemo/images/train'\nSIZE = 48 # Crop the image to 48x48\nDOWNSAMPLE_RATIO = 4 # Downsample the image by a factor of 4\n\nfor folder in os.listdir(folder_dir):\n    for file in os.listdir(os.path.join(folder_dir, folder)):\n        if file.endswith(\"jpg\"):\n            image_path = os.path.join(folder_dir, folder, file)\n            img = cv2.imread(image_path)\n            img_resized = cv2.resize(img, (SIZE, SIZE))\n            cv2.imwrite(image_path, img_resized)\n        else:\n            continue","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:15.320992Z","iopub.execute_input":"2023-04-27T12:49:15.321711Z","iopub.status.idle":"2023-04-27T12:49:25.503410Z","shell.execute_reply.started":"2023-04-27T12:49:15.321675Z","shell.execute_reply":"2023-04-27T12:49:25.502434Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"##expression = 'happy'\n##plt.style.use('dark_background')\n##plt.figure(figsize= (12,12))\n##for i in range(1, 10, 1):\n##    plt.subplot(3,3,i)\n#     img = load_img(folder_path+\"train/\"+expression+\"/\"+\n  ##  img = load_img(folder_path+\"train/\"+expression+\"/\"+\n    ##              os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n##    plt.imshow(img)   \n##plt.show()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-27T12:49:25.507025Z","iopub.execute_input":"2023-04-27T12:49:25.507307Z","iopub.status.idle":"2023-04-27T12:49:25.512804Z","shell.execute_reply.started":"2023-04-27T12:49:25.507282Z","shell.execute_reply":"2023-04-27T12:49:25.511694Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size  = 32\npicture_size = 48\ndatagen_train  = ImageDataGenerator(rescale=1./255,\n                                    rotation_range=.5,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    zoom_range=0.2,\n                                    fill_mode='nearest')\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                              target_size = (picture_size,picture_size),\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:25.514389Z","iopub.execute_input":"2023-04-27T12:49:25.515038Z","iopub.status.idle":"2023-04-27T12:49:25.849574Z","shell.execute_reply.started":"2023-04-27T12:49:25.515002Z","shell.execute_reply":"2023-04-27T12:49:25.848581Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 2827 images belonging to 5 classes.\nFound 797 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nfrom keras.layers import BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:25.851113Z","iopub.execute_input":"2023-04-27T12:49:25.851465Z","iopub.status.idle":"2023-04-27T12:49:25.859269Z","shell.execute_reply.started":"2023-04-27T12:49:25.851431Z","shell.execute_reply":"2023-04-27T12:49:25.858342Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\n\n\nno_of_classes = 5\n\nwith stg.scope():\n    pre_trained_model = VGG16(input_shape=(48,48,3), include_top=False,\n                          weights=\"/kaggle/input/vgg16v1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n    \n    for layer in pre_trained_model.layers:\n        layer.trainable = False\n\n    last_layer = pre_trained_model.get_layer('block1_conv1')\n    last_output = last_layer.output\n    \n    # Flatten the output layer to 1 dimension\n    x = Conv2D(128, (3,3))(last_output)\n    # Add a fully connected layer with 512 hidden units and ReLU activation\n\n    vgm = Model(pre_trained_model.input, x)\n    model = Sequential()\n    model.add(vgm)\n    #1st CNN layer\n    model.add(Conv2D(64, (3,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    #2nd CNN layer\n    model.add(Conv2D(128,(5,5),padding = 'same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout (0.25))\n\n    #3rd CNN layer\n    model.add(Conv2D(512,(3,3),padding = 'same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout (0.25))\n\n    #4th CNN layer\n    model.add(Conv2D(512,(3,3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    #Fully connected 1st layer\n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n\n    # Fully connected layer 2nd layer\n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n\n    # Fully connected layer 3rd layer\n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.22))\n\n    model.add(Dense(no_of_classes, activation='softmax'))\n\n    opt = Adam(learning_rate = 0.0001)\n    model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:25.861039Z","iopub.execute_input":"2023-04-27T12:49:25.861599Z","iopub.status.idle":"2023-04-27T12:49:27.086362Z","shell.execute_reply.started":"2023-04-27T12:49:25.861565Z","shell.execute_reply":"2023-04-27T12:49:27.085332Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmodel (Functional)           (None, 46, 46, 128)       75648     \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 44, 44, 64)        73792     \n_________________________________________________________________\nactivation (Activation)      (None, 44, 44, 64)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 22, 22, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 22, 22, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 22, 22, 128)       204928    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 22, 22, 128)       512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 22, 22, 128)       0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 11, 11, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 512)       590336    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 11, 11, 512)       2048      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 11, 11, 512)       0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 5, 5, 512)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 5, 5, 512)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 5, 5, 512)         2359808   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 5, 5, 512)         2048      \n_________________________________________________________________\nactivation_3 (Activation)    (None, 5, 5, 512)         0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 2, 2, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               524544    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 256)               1024      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 256)               0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               131584    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 512)               2048      \n_________________________________________________________________\nactivation_5 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 512)               2048      \n_________________________________________________________________\nactivation_6 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 2565      \n=================================================================\nTotal params: 4,235,589\nTrainable params: 4,228,933\nNon-trainable params: 6,656\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop,SGD,Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 64\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(learning_rate=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:27.087909Z","iopub.execute_input":"2023-04-27T12:49:27.088254Z","iopub.status.idle":"2023-04-27T12:49:27.105817Z","shell.execute_reply.started":"2023-04-27T12:49:27.088221Z","shell.execute_reply":"2023-04-27T12:49:27.104801Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_set,\n                    steps_per_epoch=train_set.n//train_set.batch_size,\n                    epochs=epochs,\n                    validation_data = test_set,\n                    validation_steps = test_set.n//test_set.batch_size,\n                    callbacks=callbacks_list\n                    )","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:49:27.109009Z","iopub.execute_input":"2023-04-27T12:49:27.109303Z","iopub.status.idle":"2023-04-27T12:50:31.987452Z","shell.execute_reply.started":"2023-04-27T12:49:27.109278Z","shell.execute_reply":"2023-04-27T12:50:31.986453Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/64\n88/88 [==============================] - 20s 99ms/step - loss: 1.8526 - accuracy: 0.2701 - val_loss: 4434.6230 - val_accuracy: 0.2174\nEpoch 2/64\n88/88 [==============================] - 6s 71ms/step - loss: 1.5732 - accuracy: 0.3624 - val_loss: 3001.6887 - val_accuracy: 0.1107\nEpoch 3/64\n88/88 [==============================] - 6s 70ms/step - loss: 1.4041 - accuracy: 0.4190 - val_loss: 1810.0820 - val_accuracy: 0.2227\nEpoch 4/64\n88/88 [==============================] - 6s 74ms/step - loss: 1.1599 - accuracy: 0.5388 - val_loss: 2441.3411 - val_accuracy: 0.1107\nEpoch 5/64\n88/88 [==============================] - 6s 73ms/step - loss: 0.8994 - accuracy: 0.6397 - val_loss: 750.0030 - val_accuracy: 0.2943\nEpoch 6/64\n88/88 [==============================] - 6s 71ms/step - loss: 0.6933 - accuracy: 0.7395 - val_loss: 1883.2427 - val_accuracy: 0.3307\nEpoch 7/64\n88/88 [==============================] - 6s 71ms/step - loss: 0.6103 - accuracy: 0.7667 - val_loss: 2598.9834 - val_accuracy: 0.1081\nEpoch 8/64\n88/88 [==============================] - 6s 72ms/step - loss: 0.4961 - accuracy: 0.8165 - val_loss: 2545.4436 - val_accuracy: 0.2826\nRestoring model weights from the end of the best epoch.\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 00008: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_set)\nprint('Test accuracy:', test_acc)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-04-27T12:50:31.989751Z","iopub.execute_input":"2023-04-27T12:50:31.990546Z","iopub.status.idle":"2023-04-27T12:50:33.015977Z","shell.execute_reply.started":"2023-04-27T12:50:31.990508Z","shell.execute_reply":"2023-04-27T12:50:33.015062Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"25/25 [==============================] - 1s 34ms/step - loss: 745.4232 - accuracy: 0.2911\nTest accuracy: 0.29109159111976624\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/my_model_emo.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:50:33.019025Z","iopub.execute_input":"2023-04-27T12:50:33.019309Z","iopub.status.idle":"2023-04-27T12:50:33.208564Z","shell.execute_reply.started":"2023-04-27T12:50:33.019283Z","shell.execute_reply":"2023-04-27T12:50:33.207590Z"},"trusted":true},"execution_count":12,"outputs":[]}]}
